{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class rag_model_response:\n",
    "    def __init__(self,llm_model_obj):\n",
    "        self.llm_model_obj = llm_model_obj\n",
    "    \n",
    "    def streaming(self):\n",
    "        return self.llm_model_obj.stream()\n",
    "    \n",
    "    def cost_estimate(self):\n",
    "        self.llm_model_obj.cost_details()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Base class declaration for llm \n",
    "from abc import ABC,abstractmethod\n",
    "\n",
    "class llm_model_pattern(ABC):\n",
    "    @abstractmethod\n",
    "    def stream(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def cost_details(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def connection():\n",
    "    ind = 10\n",
    "    while ind>=0:\n",
    "        ind-=1\n",
    "        yield \"data is \"+ f\" {ind}\"\n",
    "\n",
    "class azure_open_ai(llm_model_pattern):\n",
    "    def __init__(self,model_name):\n",
    "        self.model_deployment = connection\n",
    "        \n",
    "    \n",
    "    def stream(self):\n",
    "        return self.model_deployment()\n",
    "    def cost_details(self):\n",
    "        \n",
    "        return \"some_random_cost for now\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating rag pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is  9\n",
      "data is  8\n",
      "data is  7\n",
      "data is  6\n",
      "data is  5\n",
      "data is  4\n",
      "data is  3\n",
      "data is  2\n",
      "data is  1\n",
      "data is  0\n",
      "data is  -1\n"
     ]
    }
   ],
   "source": [
    "gpt_model = azure_open_ai(\"gpt-4\")\n",
    "\n",
    "rag_pipeline = rag_model_response(gpt_model)\n",
    "\n",
    "for data in rag_pipeline.streaming():\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance thing to add\n",
    ":) path 0\n",
    "- container check if case of rag model.\n",
    "\n",
    ":) path 1 (llm model call)\n",
    "- cost calculation\n",
    "- citation pdf in case of cognitive search\n",
    "- streaming response\n",
    "- comparision scores\n",
    "- make restrival model class as well\n",
    "\n",
    ":) path 2 (db save)\n",
    "- saving this data into the mysql\n",
    "- restriving data from mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class database_operation:\n",
    "    def saving_chat_data(self,db_model_obj,model_data,model_que):\n",
    "        db_model_obj.saving(model_data,model_que)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
